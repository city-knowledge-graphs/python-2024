{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd2d5f1",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02cb05c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ernesto/Documents/City_Teaching/venv_python/lab2/lib/python3.8/site-packages/rdflib_jsonld/__init__.py:9: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#To import libraries in the parent folder\n",
    "sys.path.append(\"../\")\n",
    "from rdflib import Graph\n",
    "from rdflib import URIRef, BNode, Literal\n",
    "from rdflib import Namespace\n",
    "from rdflib.namespace import OWL, RDF, RDFS, FOAF, XSD\n",
    "from rdflib.util import guess_format\n",
    "import pandas as pd\n",
    "from isub import isub\n",
    "from lookup import DBpediaLookup\n",
    "import csv\n",
    "import owlrl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee0af5",
   "metadata": {},
   "source": [
    "### All Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5de0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Adapted on 05 March 2024\n",
    "\n",
    "@author: ejimenez-ruiz\n",
    "'''\n",
    "class Lab5Solution(object):\n",
    "    '''\n",
    "    Example of a partial solution for Lab 5 \n",
    "    '''\n",
    "    def __init__(self, input_file):\n",
    "   \n",
    "        #The idea is to cover as much as possible from the original csv file, but for the lab and coursework I'm more interested \n",
    "        #in the ideas and proposed implementation than covering all possible cases in all rows (a perfect solution fall more into\n",
    "        #the score of a PhD project). Also in terms of scalability calling the \n",
    "        #look-up services may be expensive so if this is a limitation, a solution tested over a reasonable percentage of the original \n",
    "        #file will be of course accepted.        \n",
    "        self.file = input_file\n",
    "    \n",
    "        #Dictionary that keeps the URIs. Specially useful if accessing a remote service to get a candidate URI to avoid repeated calls\n",
    "        self.stringToURI = dict()\n",
    "        \n",
    "        \n",
    "        #1. GRAPH INITIALIZATION\n",
    "    \n",
    "        #Empty graph\n",
    "        self.g = Graph()\n",
    "        \n",
    "        #Note that this is the same namespace used in the ontology \"ontology_lab5.ttl\"\n",
    "        self.lab5_ns_str= \"http://www.semanticweb.org/ernesto/in3067-inm713/lab5/\"\n",
    "        \n",
    "        #Special namspaces class to create directly URIRefs in python.           \n",
    "        self.lab5 = Namespace(self.lab5_ns_str)\n",
    "        \n",
    "        #Prefixes for the serialization\n",
    "        self.g.bind(\"lab5\", self.lab5) #lab5 is a newly created namespace\n",
    "        self.g.bind(\"dbr\", \"http://dbpedia.org/resource/\") \n",
    "        \n",
    "        #Load data in dataframe  \n",
    "        self.data_frame = pd.read_csv(self.file, sep=',', quotechar='\"',escapechar=\"\\\\\")    \n",
    "    \n",
    "        \n",
    "        #KG\n",
    "        self.dbpedia = DBpediaLookup()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def performTask1(self):\n",
    "        self.CovertCSVToRDF(False)\n",
    "        \n",
    "    def performTask2(self):\n",
    "        self.CovertCSVToRDF(True)\n",
    "\n",
    "    \n",
    "    def SimpleUniqueMapping(self):\n",
    "        #This mapping creates an several transformations (i.e., triples) in one go.\n",
    "        #Unlike the modular approach (see ConvertCSVToRDF) this solution is less flexible to adaptations  \n",
    "        \n",
    "        #Format:\n",
    "        #0        1             2    3        4        5        6        7            8         9\n",
    "        #city     city_ascii    lat  lng    country    iso2    iso3    admin_name    capital    population                        \n",
    "        for row in self.data_frame.itertuples(index=False):\n",
    "            #print(row[0])\n",
    "                                    \n",
    "            #we avoid NaN values, one could add more safety filters. This case is problematic in this dataset                            \n",
    "            if (self.is_nan(row[1]) or self.is_nan(row[4])): \n",
    "                continue\n",
    "                \n",
    "            entity_city_uri = self.lab5_ns_str + row[1].lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "            entity_country_uri = self.lab5_ns_str + row[4].lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "                                \n",
    "            #Types triples\n",
    "            #Using self.lab5.City is equivalent to using URIRef(self.lab5_ns_str = \"City\")\n",
    "            self.g.add((URIRef(entity_city_uri), RDF.type, self.lab5.City))     #e.g. lab5:london rdf:type lab5:City\n",
    "            self.g.add((URIRef(entity_country_uri), RDF.type, self.lab5.Country))  #e.g. lab5united_kingdom rdf:type lab5:Country\n",
    "        \n",
    "            #City Names triples            \n",
    "            self.g.add((URIRef(entity_city_uri), self.lab5.name_ascii, Literal(row[1], datatype=XSD.string)))\n",
    "            if (not self.is_nan(row[0])):\n",
    "                self.g.add((URIRef(entity_city_uri), self.lab5.name, Literal(row[0], datatype=XSD.string)))\n",
    "            if (not self.is_nan(row[7])):\n",
    "                self.g.add((URIRef(entity_city_uri), self.lab5.admin_name, Literal(row[7], datatype=XSD.string)))\n",
    "                       \n",
    "                       \n",
    "            #Lat & long\n",
    "            if (not self.is_nan(row[2])):\n",
    "                self.g.add((URIRef(entity_city_uri), self.lab5.latitude, Literal(row[2], datatype=XSD.float)))\n",
    "            if (not self.is_nan(row[3])):\n",
    "                self.g.add((URIRef(entity_city_uri), self.lab5.longitude, Literal(row[3], datatype=XSD.float)))\n",
    "            \n",
    "            #population\n",
    "            if (not self.is_nan(row[9])):\n",
    "                self.g.add((URIRef(entity_city_uri), self.lab5.population, Literal(row[9], datatype=XSD.long)))\n",
    "                       \n",
    "            \n",
    "            #Country name triple            \n",
    "            self.g.add((URIRef(entity_country_uri), self.lab5.name, Literal(row[4], datatype=XSD.string)))\n",
    "            \n",
    "        \n",
    "            #iso codes\n",
    "            if (not self.is_nan(row[5])):\n",
    "                self.g.add((URIRef(entity_country_uri), self.lab5.iso2code, Literal(row[5], datatype=XSD.string)))\n",
    "            if (not self.is_nan(row[6])):\n",
    "                self.g.add((URIRef(entity_country_uri), self.lab5.iso3code, Literal(row[6], datatype=XSD.string)))\n",
    "             \n",
    "             \n",
    "            \n",
    "            #Connection between cities and countries\n",
    "            \n",
    "            #Basic connection ignoring column \"capital\":                        \n",
    "            #self.g.add((URIRef(entity_city_uri), self.lab5.cityIsLocatedIn, URIRef(entity_country_uri)))\n",
    "            \n",
    "            \n",
    "            #Exploiting 'capital' column (it can be empty)            \n",
    "                \n",
    "            #(default) if value is empty or not expected\n",
    "            predicate = self.lab5.cityIsLocatedIn\n",
    "                \n",
    "            if row[8]==\"admin\":                      \n",
    "                predicate = self.lab5.isFirstLevelAdminCapitalOf\n",
    "            elif row[8]==\"primary\":\n",
    "                predicate = self.lab5.isCapitalOf                        \n",
    "            elif row[8]==\"minor\":\n",
    "                predicate = self.lab5.isSecondLevelAdminCapitalOf\n",
    "                \n",
    "            \n",
    "            #Note that the ontology in lab5.ttl contains a hierarchy of properties, range and domain axioms and inverses\n",
    "            #Via reasoning this triple will lead to several entailments\n",
    "            self.g.add((URIRef(entity_city_uri), predicate, URIRef(entity_country_uri)))\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    def CovertCSVToRDF(self, useExternalURI):\n",
    "                 \n",
    "        #In a large ontology one would need to find a more automatic way to use the ontology vocabulary. \n",
    "        #E.g.,  via matching. In a similar way as we match entities to a large KG like DBPedia or Wikidata\n",
    "        #Since we are dealing with very manageable ontologies, we can integrate their vocabulary \n",
    "        #within the code. E.g.,: lab5.City\n",
    "        \n",
    "        \n",
    "        #We modularize the transformation to RDF. The transformation is tailored to the given table, but \n",
    "        #the individual components/mappings are relatively generic (especially type and literal triples).\n",
    "        \n",
    "        #Mappings may required one or more columns as input and create 1 or more triples for an entity\n",
    "        \n",
    "        \n",
    "        if 'country' in self.data_frame:\n",
    "            \n",
    "            #We give subject column and target type\n",
    "            self.mappingToCreateTypeTriple('country', self.lab5.Country, useExternalURI)\n",
    "            \n",
    "            #We give subject and object columns (they could be the same), predicate and datatype \n",
    "            self.mappingToCreateLiteralTriple('country', 'country', self.lab5.name, XSD.string)\n",
    "            \n",
    "            \n",
    "            if 'iso2' in self.data_frame:\n",
    "                self.mappingToCreateLiteralTriple('country', 'iso2', self.lab5.iso2code, XSD.string)\n",
    "            \n",
    "            if 'iso3' in self.data_frame:\n",
    "                self.mappingToCreateLiteralTriple('country', 'iso3', self.lab5.iso3code, XSD.string)\n",
    "            \n",
    "            \n",
    "                \n",
    "        if 'city_ascii' in self.data_frame:\n",
    "            self.mappingToCreateTypeTriple('city_ascii', self.lab5.City, useExternalURI)\n",
    "            self.mappingToCreateLiteralTriple('city_ascii', 'city_ascii', self.lab5.name_ascii, XSD.string)\n",
    "        \n",
    "        \n",
    "            if 'city' in self.data_frame:\n",
    "                self.mappingToCreateLiteralTriple('city_ascii', 'city', self.lab5.name, XSD.string)\n",
    "\n",
    "            \n",
    "            if 'admin_name' in self.data_frame:\n",
    "               self.mappingToCreateLiteralTriple('city_ascii', 'admin_name', self.lab5.admin_name, XSD.string)\n",
    "        \n",
    "        \n",
    "            \n",
    "            if 'lat' in self.data_frame:\n",
    "                self.mappingToCreateLiteralTriple('city_ascii', 'lat', self.lab5.latitude, XSD.float)\n",
    "                \n",
    "            if 'lng' in self.data_frame:\n",
    "                self.mappingToCreateLiteralTriple('city_ascii', 'lng', self.lab5.longitude, XSD.float)\n",
    "                \n",
    "            if 'population' in self.data_frame:\n",
    "                self.mappingToCreateLiteralTriple('city_ascii', 'population', self.lab5.population, XSD.long)\n",
    "        \n",
    "            \n",
    "            \n",
    "            if 'capital' in self.data_frame:\n",
    "                #Special tailored mapping. We give column for subjects and objects \n",
    "                #and the column including the type of capital                \n",
    "                self.mappingToCreateCapitalTriple('city_ascii', 'country', 'capital')\n",
    "                \n",
    "                #Alternative simpler mapping, but it does not consider capital information\n",
    "                #self.mappingToCreateObjectTriple('city_ascii', 'country', self.lab5.cityIsLocatedIn)\n",
    "\n",
    "        \n",
    "    \n",
    "    def processLexicalName(self, name):\n",
    "        #Remove potential spaces and other characters not allowed in URIs\n",
    "        \n",
    "        #This method may need to be extended\n",
    "        #Other problematic characters: \n",
    "        #{\", \"}\", \"|\", \"\\\", \"^\", \"~\", \"[\", \"]\", and \"`\"\n",
    "        return name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        \n",
    "        \n",
    "        \n",
    "          \n",
    "    def createURIForEntity(self, name, useExternalURI):\n",
    "        \n",
    "        #We create fresh URI (default option)\n",
    "        self.stringToURI[name] = self.lab5_ns_str + self.processLexicalName(name)\n",
    "        \n",
    "        if useExternalURI: #We connect to online KG\n",
    "            uri = self.getExternalKGURI(name)\n",
    "            if uri!=\"\":\n",
    "                self.stringToURI[name]=uri\n",
    "        \n",
    "        return self.stringToURI[name]\n",
    "    \n",
    "    \n",
    "        \n",
    "    def getExternalKGURI(self, name):\n",
    "        '''\n",
    "        Approximate solution: We get the entity with highest lexical similarity\n",
    "        The use of context may be necessary in some cases        \n",
    "        '''\n",
    "        \n",
    "        entities = self.dbpedia.getKGEntities(name, 5)\n",
    "        #print(\"Entities from DBPedia:\")\n",
    "        current_sim = -1\n",
    "        current_uri=''\n",
    "        for ent in entities:           \n",
    "            isub_score = isub(name, ent.label) \n",
    "            if current_sim < isub_score:\n",
    "                current_uri = ent.ident\n",
    "                current_sim = isub_score\n",
    "        \n",
    "            #print(current_uri)\n",
    "        return current_uri \n",
    "            \n",
    "    \n",
    "    '''\n",
    "    Mapping to create triples like lab5:London rdf:type lab5:City\n",
    "    A mapping may create more than one triple\n",
    "    column: columns where the entity information is stored\n",
    "    useExternalURI: if URI is fresh or from external KG\n",
    "    '''\n",
    "    def mappingToCreateTypeTriple(self, subject_column, class_type, useExternalURI):\n",
    "        \n",
    "        for subject in self.data_frame[subject_column]:\n",
    "                \n",
    "            #We use the ascii name to create the fresh URI for a city in the dataset\n",
    "            if subject.lower() in self.stringToURI:\n",
    "                entity_uri=self.stringToURI[subject.lower()]\n",
    "            else:\n",
    "                entity_uri=self.createURIForEntity(subject.lower(), useExternalURI)\n",
    "            \n",
    "            #TYPE TRIPLE\n",
    "            #For the individuals we use URIRef to create an object \"URI\" out of the string URIs\n",
    "            #For the concepts we use the ones in the ontology and we are using the NameSpace class\n",
    "            #Alternatively one could use URIRef(self.lab5_ns_str+\"City\") for example \n",
    "            self.g.add((URIRef(entity_uri), RDF.type, class_type))\n",
    "        \n",
    "\n",
    "                        \n",
    "            \n",
    "\n",
    "\n",
    "    def is_nan(self, x):\n",
    "        return (x != x)\n",
    "            \n",
    "            \n",
    "    '''\n",
    "    Mappings to create triples of the form lab5:london lab5:name \"London\"\n",
    "    '''    \n",
    "    def mappingToCreateLiteralTriple(self, subject_column, object_column, predicate, datatype):\n",
    "        \n",
    "        for subject, lit_value in zip(self.data_frame[subject_column], self.data_frame[object_column]):\n",
    "            \n",
    "            if self.is_nan(lit_value) or lit_value==None or lit_value==\"\":\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                #Uri as already created\n",
    "                entity_uri=self.stringToURI[subject.lower()]\n",
    "                    \n",
    "                #Literal\n",
    "                lit = Literal(lit_value, datatype=datatype)\n",
    "                \n",
    "                #New triple\n",
    "                self.g.add((URIRef(entity_uri), predicate, lit))\n",
    "            \n",
    "    '''\n",
    "    Mappings to create triples of the form lab5:london lab5:cityIsLocatedIn lab5:united_kingdom\n",
    "    '''\n",
    "    def mappingToCreateObjectTriple(self, subject_column, object_column, predicate):\n",
    "        \n",
    "        for subject, object in zip(self.data_frame[subject_column], self.data_frame[object_column]):\n",
    "            \n",
    "            if self.is_nan(object):\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                #Uri as already created\n",
    "                subject_uri=self.stringToURI[subject.lower()]\n",
    "                object_uri=self.stringToURI[object.lower()]\n",
    "                    \n",
    "                #New triple\n",
    "                self.g.add((URIRef(subject_uri), predicate, URIRef(object_uri)))\n",
    "            \n",
    "    \n",
    "    \n",
    "    def mappingToCreateCapitalTriple(self, subject_column, object_column, capital_value_column):\n",
    "        \n",
    "        for subject, object, value in zip(self.data_frame[subject_column], self.data_frame[object_column], self.data_frame[capital_value_column]):\n",
    "            \n",
    "            #URI as already created\n",
    "            subject_uri=self.stringToURI[subject.lower()]\n",
    "            object_uri=self.stringToURI[object.lower()]\n",
    "            \n",
    "            \n",
    "            #(default) if value is empty or not expected\n",
    "            predicate = self.lab5.cityIsLocatedIn\n",
    "            \n",
    "            if value==\"admin\":                      \n",
    "                predicate = self.lab5.isFirstLevelAdminCapitalOf\n",
    "            elif value==\"primary\":\n",
    "                predicate = self.lab5.isCapitalOf                        \n",
    "            elif value==\"minor\":\n",
    "                predicate = self.lab5.isSecondLevelAdminCapitalOf\n",
    "            \n",
    "            \n",
    "            #New triple\n",
    "            #Note that the ontology in lab5.ttl contains a hierarchy of properties, range and domain axioms and inverses\n",
    "            #Via reasoning this triple will lead to several entailments\n",
    "            self.g.add((URIRef(subject_uri), predicate, URIRef(object_uri)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    def performReasoning(self, ontology_file):\n",
    "        \n",
    "        #We expand the graph with the inferred triples\n",
    "        #We use owlrl library with OWL2 RL Semantics (instead of RDFS semantic as we saw in lab 4)\n",
    "        #More about OWL 2 RL Semantics in lecture/lab 7\n",
    "        \n",
    "        print(\"Data triples from CSV: '\" + str(len(self.g)) + \"'.\")\n",
    "    \n",
    "    \n",
    "        #We should load the ontology first\n",
    "        #print(guess_format(ontology_file))\n",
    "        self.g.load(ontology_file,  format=guess_format(ontology_file)) #e.g., format=ttl\n",
    "        \n",
    "        \n",
    "        print(\"Triples including ontology: '\" + str(len(self.g)) + \"'.\")\n",
    "        \n",
    "        \n",
    "        #We apply reasoning and expand the graph with new triples \n",
    "        owlrl.DeductiveClosure(owlrl.OWLRL_Semantics, axiomatic_triples=False, datatype_axioms=False).expand(self.g)\n",
    "        \n",
    "        print(\"Triples after OWL 2 RL reasoning: '\" + str(len(self.g)) + \"'.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def performSPARQLQuery(self, file_query_out):\n",
    "        \n",
    "        qres = self.g.query(\n",
    "            \"\"\"SELECT DISTINCT ?country ?city ?pop WHERE {\n",
    "              ?city rdf:type lab5:City .\n",
    "              ?city lab5:isCapitalOf ?country .\n",
    "              ?city lab5:population ?pop .\n",
    "              FILTER (xsd:integer(?pop) > 5000000)\n",
    "        }\n",
    "        ORDER BY DESC(?pop)\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "        print(\"%s capitals satisfying the query.\" % (str(len(qres))))\n",
    "        \n",
    "        f_out = open(file_query_out,\"w+\")\n",
    "\n",
    "        for row in qres:\n",
    "            #Row is a list of matched RDF terms: URIs, literals or blank nodes\n",
    "            line_str = '\\\"%s\\\",\\\"%s\\\",\\\"%s\\\"\\n' % (row.country, row.city, row.pop)\n",
    "\n",
    "\n",
    "            f_out.write(line_str)\n",
    "            \n",
    "     \n",
    "        f_out.close()       \n",
    "        \n",
    "        \n",
    "    def performSPARQLQueryLab7(self):\n",
    "        \n",
    "        qres = self.g.query(\n",
    "            \"\"\"SELECT DISTINCT ?country (COUNT(?city) AS ?num_cities) WHERE { \n",
    "              ?country lab5:hasCity ?city .\n",
    "        }\n",
    "        GROUP BY ?country\n",
    "        ORDER BY DESC(?num_cities)\n",
    "        \"\"\")\n",
    "\n",
    "\n",
    "   \n",
    "        for row in qres:\n",
    "            #Row is a list of matched RDF terms: URIs, literals or blank nodes\n",
    "            line_str = '\\\"%s\\\",\\\"%s\\\"' % (row.country, row.num_cities)\n",
    "            print(line_str)\n",
    "\n",
    "     \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def saveGraph(self, file_output):\n",
    "        \n",
    "        ##SAVE/SERIALIZE GRAPH\n",
    "        #print(self.g.serialize(format=\"turtle\").decode(\"utf-8\"))\n",
    "        self.g.serialize(destination=file_output, format='ttl')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c031f9e",
   "metadata": {},
   "source": [
    "### Task Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ead8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data triples from CSV: '914'.\n",
      "Triples including ontology: '1027'.\n",
      "Triples after OWL 2 RL reasoning: '3748'.\n",
      "24 capitals satisfying the query.\n"
     ]
    }
   ],
   "source": [
    "#Initialization \n",
    "#Format:\n",
    "#city    city_ascii    lat    lng    country    iso2    iso3    admin_name    capital    population\n",
    "file = \"../data/worldcities-free-100.csv\"\n",
    "output_file_name = \"worldcities-free-100\"\n",
    "\n",
    "solution = Lab5Solution(file)\n",
    "\n",
    "#Solution task 1\n",
    "task = \"task1\"\n",
    "#Solution task 1\n",
    "#task = \"task2\" # May take a few seconds\n",
    "#Instead of having several small mappings the transformation is done using a single function or mapping\n",
    "#task = \"Simple_Mapping\"\n",
    "    \n",
    "#Create RDF triples\n",
    "if task == \"task1\":\n",
    "    solution.performTask1()  #Fresh entity URIs\n",
    "elif task == \"task2\":\n",
    "    solution.performTask2()  #Reusing URIs from DBPedia\n",
    "else:\n",
    "    solution.SimpleUniqueMapping()  #Simple and unique mapping/transformation\n",
    "        \n",
    "    \n",
    "#Graph with only data\n",
    "solution.saveGraph(\"./data/\"+output_file_name+\"-\"+task+\".ttl\")\n",
    "\n",
    "    \n",
    "#OWL 2 RL reasoning\n",
    "#We will see reasoning next week. Not strictly necessary for this \n",
    "solution.performReasoning(\"../data/ontology_lab5.ttl\") ##ttl format\n",
    "\n",
    "    \n",
    "#Graph with ontology triples and entailed triples       \n",
    "solution.saveGraph(\"./data/\"+output_file_name+\"-\"+task+\"-reasoning.ttl\")\n",
    "    \n",
    "#SPARQL results into CSV\n",
    "solution.performSPARQLQuery(\"./data/\"+output_file_name+\"-\"+task+\"-query-results.csv\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44130e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
